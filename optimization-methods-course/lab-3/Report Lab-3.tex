\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{arcs}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}
\usepackage{graphicx}
\usepackage{setspace}
\DeclareGraphicsExtensions{.png, .jpeg}
\graphicspath{{images/}}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{stackrel}
\usepackage{xcolor}
\usepackage{minted}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{mathtools}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
}

\begin{document}
\begin{titlepage}
    \bfseries 
        {\centering
            \vspace*{14em}
            \Huge Методы оптимизации\par
            \bigbreak
            Отчёт по лабораторной работе №3 \par
        }
    \vspace{20em}
    \begin{spacing}{2}
        \begin{flushright}
            {\Large \textbf{Выполнили:}}  \\
            {\large Евсеева Арина M3234} \\
            {\large Шульпин Егор M3232} \\
            {\large Гаврилюк Виталий M3232} \\ 
        \end{flushright}
    \end{spacing}
\end{titlepage}

\newpage
\section*{Постановка задачи}
\subsection*{1. Предисловие. Задача линейной регрессии;}
\subsection*{2. Стохастический градиентный спуск с разным размером батча;}
\subsection*{3. Стохастический градиентный спуск с функцией изменения шага;}
\subsection*{4. Модификации стохастического градиентного спуска (с использованием TensorFlow):}
\begin{itemize}
    \item \textbf{Momentum;}
    \item \textbf{Nesterov;}
    \item \textbf{Adaptive gradient algorithm (AdaGrad);}
    \item \textbf{Root Mean Square Propagation (RMSProp);}
    \item \textbf{Adaptive Moment Estimation (Adam);}
\end{itemize}
\subsection*{5. Стохастический градиентный спуск для полиномиальной регрессии с добавлением регуляризации в модель разных методов регуляризации (L1, L2, Elastic);}
\subsection*{6. Решение одной из задач машинного обучения.}
\subsection*{\href{https://gitfront.io/r/Vitaliy-X-0/TLNs9s2iAaGd/MetOpt/}{Итоговая реализация}}

\newpage
\section*{Задача линейной регрессии}
Линейная регрессия - используемая в статистике регрессионная модель зависимости одной переменной $y$ от другой или нескольких других независимых переменных (регрессоров) $x$ с линейной функцией зависимости. Если имеется несколько независимых переменных $(x_1, x_2, \dots, x_n)$, то модель линейной регрессии может быть представлена в виде: $y = w_1 \cdot x_1 + w_2 \cdot x_2 + \dots + w_n \cdot x_n + b$, где:
\begin{itemize}
    \item $x$ - независимая переменная;
    \item $w$ - коэффициент наклона линии регрессии;
    \item $b$ - смещение (относительно начала координат);
    \item $y$ - предсказываемая (зависимая) величина.
\end{itemize}
Таким образом, задачей линейной регресии является поиск значений коэффициентов $w_i$ и $b$, при этом, минимизируя разницу между реальными значениями $y$ и предсказанными $\hat{y}$, где разница, обычно, вычисляется по формуле:
\begin{center}
    $L(w) = \dfrac{1}{m} \cdot \displaystyle \sum_{i=1}^{m}{(\hat{y_i} - y_i)^2}$.
\end{center}

\section*{Стохастический градиентный спуск с разным размером батча}
Нам может потребоваться много итераций, чтобы градиентный спуск сошелся. Более того, время выполнения одной итерации может быть очень большим хотя бы потому, что нам нужно каждый раз просмотреть весь датасет. Поэтому для каждого шага градиентного спуска будем использовать не точный градиент, а его оценку: выберем несколько батчей — посчитаем на них градиенты и усредним. Такой вид градиентного спуска называют стохастическим. \\

\noindent (SGD — stochastic gradient descent)
\subsection*{Стохастический градиентный спуск с одноэлементным батчем}
Из обучаюшего набора $p_1, p_2, ..., p_m$ будем выбирать случайный элемент $p_j$. Функция потери вычисляется только на одном элементе $p_j$: 
\begin{center}
    $H_j(w) = L(w, p_j)$. 
\end{center}
Точнее нам нужна не сама функция потерь, а ее градиент по w:
\begin{center}
    $g = \nabla H_j(w)$
\end{center}
Этот вектор g используем на очередном шаге стохастического градиентного спуска для вычисления следующего приближения $w_{k + 1}$
параметров модели по очередному приближению $w_k$:
\begin{center}
    $w_{k + 1} = w_k - \alpha \cdot g$
\end{center}
\subsection*{Стохастический градиентный спуск мини-пакетом (Mini-Batch)}
На каждом шаге используем пакет из фиксированного небольшого числа элементов обучающей выборки.Использование небольшого набора случайных элементов обучающей выборки для приближенного вычисления градиента функции потери позволяет уменьшить случайные вариации вектора градиента по сравнению с использованием только одного элемента. Мы фиксируем небольшой размер sмини-пакета. Выбираем набор из s
элементов обучающей выборки, $s \le m$:
\begin{center}
    $B = (p_{i_1}, p_{i_2}, ..., p_{i_s}) \subseteq (p_1, p_2, ..., p_m)$
\end{center}
Для мини-пакета B из s элементов функция потери вычисляется следующим образом: 
\begin{center}
    $H_B(w) = \dfrac{1}{s} \cdot \displaystyle \sum_{p \in B} L(w, p)$
\end{center}
Градиент этой функции:
\begin{center}
    $g = \nabla H_B(w)$
\end{center}
используется на очередном шаге стохастического градиентного спуска. После выполнения очередного шага формируется новый мини-пакет, состоящий либо из s случайно выбранных элементов обучающего набора.
\subsection*{Использование стохастического градиентного спуска в задаче двухмерной линейной регрессии}
Рассмотрим задачу линейной регрессии вида $y = wx + b$, которую наглядно можно показать с помощью двухмерных графиков. Функция ошибки в данном случае будет равна $H(w_k) = \displaystyle \sum_{i=1}^{n}(w_kx_i + b - y_i)^2$, a ее градиент по i-ому направлению - $\nabla H_i(w_k) = 2x_i \cdot \displaystyle \sum_{i=1}^{n}{(w_kx_i + b - y_i)}$. \\

\noindent Создадим тестовый набор данных $X, Y$, например:
\begin{minted}[linenos,frame=lines]{python}
    np.random.seed(234)
    X = 2 * np.random.rand(200, 1)
    Y = 6 * X + np.random.randn(200, 1) + 12
\end{minted}
\subsubsection*{Полученные результаты:}
\begin{center}
    \includegraphics[scale=0.5]{image/first_example_batch_1.png}
    \captionof{figure}{Результат с размером батча 1} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.5]{image/first_example_batch_32.png}
    \captionof{figure}{Результат с размером батча 32} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.5]{image/first_example_batch_50.png}
    \captionof{figure}{Результат с размером батча 50} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.5]{image/first_example_batch_64.png}
    \captionof{figure}{Результат с размером батча 64} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.5]{image/first_example_batch_100.png}
    \captionof{figure}{Результат с размером батча 100} 
    \label{fig:enter-label}
\end{center}
\includegraphics[scale=0.35]{image/first_example_result.jpeg}
\textbf{В исследовании были рассмотрены разные размеры батча: единичный и полный размер коллекции, размер половины коллекции, а также степени двойки, входящие в данный промежуток. Хорошую сходимость показал размер батча равный 32. При этом значение функции ошибки на граничных размерах было максимальным. Из чего можно сделать вывод, что батчевый градиентный спуск (с размером батча равным степени двойки) позволяет ускорить сходимость, не теряя точность.}

\section*{Стохастический градиентный спуск с функцией изменения шага}
\subsection*{Функция линейного затухания (linear decay)}
Возьмем стохастический градиентный спуск с функцией линейного затухания шага.
Значение шага будет изменяться по формуле $\alpha = max(\alpha_{min}, \alpha_{start} - it \cdot decay)$, где $\alpha_{min} -$ минимальное значение шага, $\alpha_{start} -$ начальное значение шага, $decay$ - величина уменьшения шага на каждой итерации (it). \\

\noindent Начальные параметры для сравнения обычного стохастического градиентного спуска с
постоянным шагом и стохастического градиентного спуска с функцией линейного затухания шага: \\
$\alpha_{min} = 10^{-3}$; \\
$\alpha_{start} = 10^{-1}$; \\
$decay = 10^{-3}$.

\subsection*{Ступенчатая функция (step decay)}
Еще одной функцией изменения шага может быть ступенчатая функция. При этом значение шага будет вычисляться по формуле $\alpha = \alpha_{start} \cdot \beta^{\floor*{\frac{it}{decay}}}$, где $\alpha_{start}$ - начальное значение шага, $decay$ - период затухания. \\

\noindent Начальное параметры для сравнения обычного стохастического градиентного спуска с
постоянным шагом и стохастического градиентного спуска со ступенчатой функцией шага: \\
$\alpha_{start} = 10^{-1}$; \\
$decay = 100$.

\subsection*{Сравнение функций шага}
Для сравнения разных подходов изменения шага возьмем фиксированное количество эпох $epochs = 20$ и размер батча $batch = 32$.
\begin{center}
    \includegraphics[scale=0.5]{image/second_example_standard.png}
    \captionof{figure}{SGD с фиксированным шагом} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.5]{image/second_example_linear_decay.png}
    \captionof{figure}{SGD с функцией линейного затухания} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.5]{image/second_example_step_decay.png}
    \captionof{figure}{SGD со ступенчатой функцией} 
    \label{fig:enter-label}
\end{center}
\includegraphics[scale=0.35]{image/second_example_result.jpeg}
\textbf{Исходя из полученных результатов можно сделать вывод, что лучшую сходимость имеет SGD  со ступенчатой функцией. Так же при оптимизированном выборе шага требуется меньше итераций, чем при фиксированном шаге.}

\section*{Модификации стохастического градиентного спуска (с использованием TensorFlow)}
\subsection*{Momentum}
Метод Momentum является ускорением и стабилизацией процесса оптимизации. Основная идея данного метода заключается в накапливание импульса, тем самым, учитывая предыдущие значения градиента. Такой подход помогает эффективно двигаться к глобальному минимуму, преодолевая локальные. С математической точки зрения, данный метод использует экспоненциальное сглаживание для значения градиента. На каждой итерации значения вычисляются по формулам:
\begin{center}
    $v_{k+1} = \beta \cdot v_k - \alpha \cdot \nabla f(w_k)$
\end{center}
\begin{center}
    $w_{k+1} = w_k + v_{k+1}$
\end{center}
\subsection*{Nesterov}
В 1983 году Юрием Нестеровым была предложена модификация метода Momentum, которая считает градиент не в текущей точке, а в точке, в которую мы бы пошли на предыдущем шаге. Такой подход позволяет исправлять ошибки на текущем шаге. В таком случае, значения считаются по данным формулам:
\begin{center}
    $v_{k+1} = \beta \cdot v_k - \alpha \cdot \nabla f(w_k - \beta \cdot v_k)$
\end{center}
\begin{center}
    $w_{k+1} = w_k + v_{k+1}$
\end{center}
\subsection*{AdaGrad}
Метод моментов и метод Нестерова учитывают только историю изменения градиента, но никак не связаны с самими оптимизируемыми параметрами. Идея заключается в том, что некоторые параметры могут быстрее достигать своего оптимума, чем другие. Поэтому хотелось бы параметры близкие к оптимуму менять с меньшим шагом, а более далекие – с большим.
AdaGrad реализует данную идею. В нем шаг для параметров зависит от величины их колебаний: чем они больше, тем меньше шаг. 
\begin{center}
    $G_{k+1} = G_k + (\nabla f(w_k))^2$
\end{center}
\begin{center}
    $w_{k+1} = w_k - \dfrac{\alpha}{\sqrt{G_{k+1} + \epsilon}} \cdot \nabla f(w_k)$
\end{center}
\subsection*{RMSProp}
Модификация метода AdaGrad — метод RMSprop — вместо суммы использует экспоненциальное скользящее среднее в знаменателе. Основное отличие RMSProp в том, что он вместо хранения истории квадратов по каждому параметру, просто берет корень из среднего квадратов градиентов по всем параметрам.
\begin{center}
    $G_{k+1} = \gamma \cdot G_k + (1 - \gamma) \cdot (\nabla f(w_k))^2$
\end{center}
\begin{center}
    $w_{k+1} = w_k - \dfrac{\alpha}{\sqrt{G_{k+1} + \epsilon}} \cdot \nabla f(w_k)$
\end{center}
\subsection*{Adam}
Adam достаточно часто применяется при обучении нейронных сетей. Фактически, этот алгоритм является очередной модификацией алгоритма AdaGrad, использующий сглаженные версии среднего и среднеквадратического градиентов:
\begin{center}
    $v_{k+1} = \beta_1 \cdot v_k + (1 - \beta_1) \cdot \nabla f(w_k)$
\end{center}
\begin{center}
    $G_{k+1} = \beta_2 \cdot G_k + (1 - \beta_2) \cdot (\nabla f(w_k))^2$
\end{center}
\begin{center}
    $w_{k+1} = w_k - \dfrac{\alpha}{\sqrt{G_{k+1} + \epsilon}} \cdot v_{k+1}$
\end{center}

\subsection*{Сравнение модификаций}
\subsubsection*{Тестовые данные}
Для сравнения сходимости и объему оперативной памяти необходимо создать довольно большой датасет, например, размера $10^{4}$:
\begin{minted}[linenos,frame=lines]{python}
    np.random.seed(543)
    X = -1.43 * 1.45 * np.random.rand(10000, 1)
    Y = 7 * X + 2 * np.random.rand(10000, 1)
    Z = 2 * X + 5 * Y + 10 * np.random.rand(10000, 1) + 3
\end{minted}
Для каждого метода установим одинаковые начальные параметры:
\begin{itemize}
    \item Размер батча $batch = 32$;
    \item Количество эпох $epoch = 30$.
\end{itemize}

\begin{center}
    \includegraphics[scale=0.35]{image/third_example_SGD_3d.png}
    \includegraphics[scale=0.3]{image/third_example_SGD_2d.png}
    \captionof{figure}{SGD без модификаций} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.35]{image/third_example_Momentum_3d.png}
    \includegraphics[scale=0.3]{image/third_example_Momentum_2d.png}
    \captionof{figure}{SGD с модификацией Momentum} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.35]{image/third_example_Nesterov_3d.png}
    \includegraphics[scale=0.3]{image/third_example_Nesterov_2d.png}
    \captionof{figure}{SGD с модификацией Nesterov} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.35]{image/third_example_AdaGrad_3d.png}
    \includegraphics[scale=0.3]{image/third_example_AdaGrad_2d.png}
    \captionof{figure}{SGD с модификацией AdaGrad} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.35]{image/third_example_RMSProp_3d.png}
    \includegraphics[scale=0.3]{image/third_example_RMSProp_2d.png}
    \captionof{figure}{SGD с модификацией RMSProp} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.35]{image/third_example_Adam_3d.png}
    \includegraphics[scale=0.3]{image/third_example_Adam_2d.png}
    \captionof{figure}{SGD с модификацией Adam} 
    \label{fig:enter-label}
\end{center}
\includegraphics[scale=0.35]{image/third_example_result.jpeg}
\subsubsection*{Вывод}
\begin{itemize}
    \item Метод SGD без модификаций показал худшую сходимость среди остальных методов, при этом потребляя наименьшее количество памяти.
    \item Метод Momentum является наиболее оптимальным по машинным ресурсам, при этом менее надеждным и быстросходящимся.
    \item Метод Nesterov имеет надежность и скорость сходимости на уровне метода Momentum, при этом требует большего количества машинных ресурсов.
    \item Метод AdaGrad является методом имеющим среднии характеристики по всем оцениваемым параметрам. Главный недостаток данного алгоритма – постоянное уменьшение шага обучения, так как мы складываем квадраты градиентов и делим на корень квадратный из этой величины.
    \item Методы RMSProp и Adam являются самыми надежными и быстросходящиеся методы, при это требующие большее количество машинных ресурсов.
\end{itemize}

\section*{Полиноминальная регрессия}

Полиномиальная регрессия означает приближение данных $(x_i,y_i)$ полиномом k–й степени $A(x)=a+b \cdot x + c \cdot x^2 + d \cdot x^3 +…+ h \cdot x^k. $ Задача полиноминальной регрессии заключается в нахождении полинома f(x) степени не больше k, минизирующего следующую функцию:
\begin{center}
    $H(w) = \displaystyle \sum_{i=1}^{m}(f(x_i) - y_i)^2.$
\end{center}
\section*{Методы регуляризации}
\subsection*{L1}
L1 регуляризация добавляет в функцию потерь дополнительное слагаемое налагающее штраф за сложность модели, то есть высокие веса:
\begin{center}
    $L_1 =  \displaystyle \sum_{i}^{}(y_i - y(t_i))^2 + \lambda \sum_{i}^{}|a_i|$
\end{center}
L1 обнуляет значения некоторых параметров, что в случае с линейными моделями приводит к отбору признаков.

\subsection*{L2}
L2 регуляризация так же добавляет к оптимизационной функции модели штрафную функцию:
\begin{center}
    $L_2 =  \displaystyle \sum_{i}^{}(y_i - y(t_i))^2 + \lambda \sum_{i}^{}a_i^2$
\end{center}
Эта штрафная функция является суммой квадратов весов модели, умноженных на гиперпараметр регуляризации. Это означает, что L2 регуляризация штрафует большие значения весов, заставляя их приближаться к нулю, но в отличие от L1 регуляризации не зануляет их полностью.
L2-функция — более эффективна с точки зрения вычислительных функций. L1 позволяет уменьшить значения некоторых коэффициентов до 0, то есть вывести из поля исследования лишние переменные. Это полезно, если на какое-либо явление влияют тысячи факторов и рассматривать все их оказывается бессмысленно.
\subsection*{Elastic}
Оба метода регуляризации объединены в технике эластичной сети (Elastic). Она оптимально подходит, когда независимые переменные сильно коррелированы между собой. В этих случаях модель сможет попеременно применять L1 и L2, в зависимости от того, какая лучше подходит с учетом входных данных.
\subsection*{Сравнение методов регуляризации}
Для исследования использовались два полинома степеней 8 и 9. \\

\noindent \textbf{Начальные параметры:}
\begin{itemize}
    \item Первый полином: $1 - \dfrac{x^2}{2!} + \dfrac{x^4}{4!} - \dfrac{x^6}{6!} + \dfrac{x^8}{8!}$;
    \item Второй полином: $x - \dfrac{x^3}{3!} + \dfrac{x^5}{5!} - \dfrac{x^7}{7!} + \dfrac{x^9}{9!}$;
\end{itemize}

\begin{center}
    \includegraphics[scale=0.5]{image/fourth_example_standard.png}
    \captionof{figure}{SGD без метода регуляризации} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.5]{image/fourth_example_L1.png}
    \captionof{figure}{SGD с методом L1} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.5]{image/fourth_example_L2.png}
    \captionof{figure}{SGD с методом L2} 
    \label{fig:enter-label}
\end{center}
\begin{center}
    \includegraphics[scale=0.5]{image/fourth_example_Elastic.png}
    \captionof{figure}{SGD с методом Elastic} 
    \label{fig:enter-label}
\end{center}

\quad

\noindent \textbf{Из полученных графиков можем сделать выводы:}
\begin{itemize}
    \item В работе стохастического градиентного спуска без метода регуляризации была выявлена проблема - переобучение.
    \item Все методы регуляризации смогли избежать переобучения. 
    \item L1 дает более ``плоский`` график, чем L2, однако это может привести к тому, что мы можем упустить какие-то скопления точек.
    \item Как и было заявлено Elastic оказался чем-то средним между L1 и L2.
\end{itemize}

\section*{Активное обучение}

\subsection*{Постановка задачи оптимизации в активном обучении}

Активное обучение — это подход в машинном обучении, при котором модель может выбирать наиболее информативные данные для обучения. Это особенно полезно, когда маркировка данных является дорогостоящей или трудоемкой. Основная идея активного обучения заключается в том, чтобы выбрать подмножество данных, которые принесут наибольшую пользу для улучшения модели.

\subsubsection*{Преимущества активного обучения:}
\begin{itemize}
    \item \textbf{Экономия ресурсов}: маркировка данных может быть дорогостоящей и трудоемкой, активное обучение позволяет сократить количество данных, которые необходимо разметить, выбирая только наиболее информативные примеры.
    \item \textbf{Улучшение качества модели}: выбирая наиболее информативные данные, модель может быстрее обучаться и достигать более высокой точности, чем при случайном выборе данных.
    \item \textbf{Адаптивность}: активное обучение позволяет модели адаптироваться к новым данным и изменяющимся условиям, выбирая данные, которые наиболее актуальны для текущей задачи.
\end{itemize}

\begin{center}
    \includegraphics[scale=0.5]{image/fifth_example_image.png}
    \captionof{figure}{Преимущество активного обучения} 
    \label{fig:enter-label}
\end{center}

\subsubsection*{Активное обучение основывается на нескольких ключевых концепциях:}
\begin{itemize}
    \item \textbf{Неопределенность}: модель выбирает данные для маркировки, в которых она наиболее неуверенна. Так модель может сосредоточиться на примерах, которые смогут улучшить её способности.
    \item \textbf{Разнообразие}: выбирает данные, которые представляют различные аспекты данных, чтобы избежать переобучения на однотипных примерах и улучшить обобщающую способность модели.
    \item \textbf{Информативность}: выбирает данные, которые, как ожидается, принесут наибольшую пользу для обучения, основываясь на различных критериях, таких как изменение параметров модели или прирост информации.
\end{itemize}

\subsubsection*{Процесс активного обучения обычно включает следующие шаги:}
\begin{enumerate}
    \item \textbf{Инициализация}: начальная модель обучается на небольшом наборе размеченных данных.
    \item \textbf{Выбор данных}: модель предсказывает метки для неразмеченных данных и выбирает наиболее информативные примеры для маркировки.
    \item \textbf{Маркировка данных}: выбранные данные передаются на разметку экспертам.
    \item \textbf{Обновление модели}: модель переобучается на обновленном наборе данных, включающем новые размеченные примеры.
    \item \textbf{Повторение}: процесс выбора данных, маркировки и обновления модели повторяется до тех пор, пока не будет достигнута желаемая точность или не исчерпан бюджет на маркировку.
\end{enumerate}

\subsection*{Пример решения задачи активного обучения для спам-фильтра}

\noindent \textbf{Задача}: создание спам-фильтра для классификации электронных писем на спам и не спам.\\

\noindent \textbf{Цель}: оптимизировать процесс выбора писем для маркировки, чтобы минимизировать количество размеченных данных, необходимых для достижения высокой точности модели.

\subsubsection*{Формулировка задачи}

\begin{itemize}
    \item Дано: большой набор неразмеченных писем \(U\) и небольшой набор размеченных писем \(L\).
    \item Найти: подмножество писем из \(U\), которые, будучи размеченными, максимально улучшат модель спам-фильтра.
\end{itemize}

\noindent \textbf{Целевая функция}: максимизировать прирост информации или уменьшить неопределенность модели.\\

\noindent \textbf{Ограничения}: ограниченное количество писем, которые можно разметить (например, бюджет на маркировку).

\subsubsection*{Методы выбора данных:}
\begin{itemize}
    \item Неопределенность.
    \item Разнообразие.
    \item Информативность.
\end{itemize}

\subsection*{Решение задачи}

\subsubsection*{Начальная фаза}

Собирается небольшой набор размеченных писем \(L\), который используется для начального обучения модели. Большой набор неразмеченных писем \(U\) остается доступным для выбора данных.

\subsubsection*{Обучение начальной модели}

Модель спам-фильтра обучается на начальном размеченном наборе \(L\).

\subsubsection*{Выбор данных для маркировки}
\begin{itemize}
    \item Модель предсказывает метки для писем из набора \(U\).
    \item Используя метод неопределенности, выбираются письма, для которых модель наиболее неуверенна (например, предсказания близки к порогу классификации).
    \item Эти письма передаются на разметку.
\end{itemize}

\subsubsection*{Обновление размеченного набора}

Размеченные письма добавляются в набор \(L\). Неразмеченные письма удаляются из набора \(U\).

\subsubsection*{Повторение процесса}

Модель переобучается на обновленном наборе \(L\). Процесс выбора данных для маркировки повторяется до тех пор, пока не будет достигнута желаемая точность или не исчерпан бюджет на маркировку.

\subsubsection*{Оценка модели}

После завершения активного обучения модель оценивается на тестовом наборе данных, чтобы проверить её точность и способность классифицировать новые письма.

\section*{Пример иллюстрации задачи}

\subsubsection*{Сценарий}

У нас есть 10,000 неразмеченных писем и 100 размеченных писем. Мы хотим создать спам-фильтр, который будет классифицировать письма с высокой точностью, но у нас ограниченный бюджет на разметку дополнительных писем.

\subsubsection*{Шаги}

\begin{enumerate}
    \item \textbf{Начальная модель}. Обучаем начальную модель на 100 размеченных письмах. Модель может быть не очень точной из-за малого количества данных.
    \item \textbf{Активное обучение}.
    \begin{itemize}
        \item Применяем модель к 10,000 неразмеченным письмам.
        \item Выбираем 200 писем, для которых модель наиболее неуверенна (например, вероятность спама около 50\%).
        \item Отправляем эти письма на разметку.
    \end{itemize}
    \item \textbf{Обновление модели}. Добавляем 200 размеченных писем к набору размеченных данных. Переобучаем модель на 300 размеченных письмах.
    \item \textbf{Повторение}. Повторяем процесс выбора и разметки данных несколько раз, пока не достигнем желаемой точности или не исчерпаем бюджет.
    \item \textbf{Оценка}. Оцениваем финальную модель на тестовом наборе данных, чтобы убедиться в её точности и надежности.
\end{enumerate}

\noindent \textbf{Таким образом,} активное обучение позволяет эффективно использовать ограниченные ресурсы для маркировки данных, выбирая наиболее информативные письма для обучения модели спам-фильтра. Это помогает минимизировать количество размеченных данных, необходимых для достижения высокой точности модели, что особенно важно в условиях ограниченного бюджета на разметку.

\quad

\noindent \textbf{Пример решения задачи с активным обучением был взят из:} \url{https://habr.com/ru/articles/593615/}

\end{document}
